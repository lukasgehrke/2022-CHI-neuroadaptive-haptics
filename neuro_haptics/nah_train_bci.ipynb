{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pID = 'sub-' + \"%01d\" % (id)\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "import pickle, json, os\n",
    "import scipy.io\n",
    "\n",
    "from bci_funcs import bandpass_filter_fft, calculate_velocity, gaze_remove_invalid_samples\n",
    "\n",
    "path = 'P:\\\\Lukas_Gehrke\\\\NAH\\\\data\\\\5_single-subject-EEG-analysis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior = pd.read_csv(path+os.sep+pID+os.sep+'behavior_s'+str(id)+'.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior = behavior[behavior.bad_epoch != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile) for AccuracyCm\n",
    "Q1_AccuracyCm = behavior['AccuracyCm'].quantile(0.25)\n",
    "Q3_AccuracyCm = behavior['AccuracyCm'].quantile(0.75)\n",
    "\n",
    "# Calculate IQR for AccuracyCm\n",
    "IQR_AccuracyCm = Q3_AccuracyCm - Q1_AccuracyCm\n",
    "\n",
    "# Define the lower and upper bounds for outliers in AccuracyCm\n",
    "lower_bound_AccuracyCm = Q1_AccuracyCm - 1.5 * IQR_AccuracyCm\n",
    "upper_bound_AccuracyCm = Q3_AccuracyCm + 1.5 * IQR_AccuracyCm\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile) for fix_delay\n",
    "Q1_fix_delay = behavior['fix_delay'].quantile(0.25)\n",
    "Q3_fix_delay = behavior['fix_delay'].quantile(0.75)\n",
    "\n",
    "# Calculate IQR for fix_delay\n",
    "IQR_fix_delay = Q3_fix_delay - Q1_fix_delay\n",
    "\n",
    "# Define the lower and upper bounds for outliers in fix_delay\n",
    "lower_bound_fix_delay = Q1_fix_delay - 1.5 * IQR_fix_delay\n",
    "upper_bound_fix_delay = Q3_fix_delay + 1.5 * IQR_fix_delay\n",
    "\n",
    "# Filter out the outliers\n",
    "behavior_filt = behavior[\n",
    "    (behavior['AccuracyCm'] >= lower_bound_AccuracyCm) & (behavior['AccuracyCm'] <= upper_bound_AccuracyCm) &\n",
    "    (behavior['fix_delay'] >= lower_bound_fix_delay) & (behavior['fix_delay'] <= upper_bound_fix_delay)\n",
    "]\n",
    "\n",
    "# print both behavior and behavior_filt shape with some text\n",
    "print('Behavior shape:', behavior.shape)\n",
    "print('Behavior_filt shape:', behavior_filt.shape)\n",
    "\n",
    "behavior = behavior_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context('paper', font_scale = 1.8):\n",
    "\n",
    "    ### Create new plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7,4))\n",
    "    fig.patch.set_alpha(1)\n",
    "\n",
    "    sns.despine() #bottom=True, left=True\n",
    "\n",
    "    sns.histplot(behavior_filt['answerID']) #, binwidth=1, binrange=(0.5, 5.5), kde=False)\n",
    "\n",
    "    # add xline at median\n",
    "    plt.axvline(behavior_filt['answerID'].median(), color='black', linestyle='dashed', linewidth=1)\n",
    "\n",
    "    plt.xlabel('Answer ID')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Answer ID')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order for the hapticProfile categories\n",
    "haptic_order = sorted(behavior['hapticProfile'].unique())\n",
    "\n",
    "# Convert the hapticProfile column to a categorical type with the specified order\n",
    "behavior['hapticProfile'] = pd.Categorical(behavior['hapticProfile'], categories=haptic_order, ordered=True)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 4))\n",
    "fig.patch.set_alpha(1)\n",
    "\n",
    "with sns.plotting_context('paper', font_scale=1.8):\n",
    "    sns.despine()\n",
    "    sns.boxplot(x='hapticProfile', y='answerID', data=behavior, ax=axs[0])\n",
    "    axs[0].set_xlabel('Haptic Profile')\n",
    "    axs[0].set_ylabel('Answer ID')\n",
    "\n",
    "with sns.plotting_context('paper', font_scale=1.8):\n",
    "    sns.despine()\n",
    "    sns.boxplot(x='hapticProfile', y='AccuracyCm', data=behavior, ax=axs[1])\n",
    "    axs[1].set_xlabel('Haptic Profile')\n",
    "    axs[1].set_ylabel('AccuracyCm')\n",
    "\n",
    "with sns.plotting_context('paper', font_scale=1.8):\n",
    "    sns.despine()\n",
    "    sns.boxplot(x='hapticProfile', y='fix_delay', data=behavior, ax=axs[2])\n",
    "    axs[2].set_xlabel('Haptic Profile')\n",
    "    axs[2].set_ylabel('Fixation Delay')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroadaptive Haptics BCI Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "erp = scipy.io.loadmat(path+os.sep+pID+os.sep+'erp.mat')['erp']\n",
    "gaze = scipy.io.loadmat(path+os.sep+pID+os.sep+'gaze.mat')['gaze']\n",
    "hand_motion = scipy.io.loadmat(path+os.sep+pID+os.sep+'hand_motion.mat')['hand_motion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERP\n",
    "# Apply the bandpass filter to the ERP data\n",
    "erp = bandpass_filter_fft(erp, .1, 15, 250)\n",
    "\n",
    "# Gaze\n",
    "gaze_vel = np.zeros((gaze.shape[1], gaze.shape[2]))\n",
    "# Calculate the velocity for each trial\n",
    "for i in range(gaze.shape[2]):\n",
    "    gaze_vel[:, i] = calculate_velocity(gaze[:, :, i])\n",
    "# remove invalid samples\n",
    "for i in range(gaze.shape[2]):\n",
    "    gaze_vel[:, i] = gaze_remove_invalid_samples(gaze_vel[:,i], gaze[-1,:,i])\n",
    "\n",
    "# Hand motion\n",
    "hand_vel = np.zeros((hand_motion.shape[1], hand_motion.shape[2]))\n",
    "# Calculate the velocity for each trial\n",
    "for i in range(hand_motion.shape[2]):\n",
    "    hand_vel[:, i] = calculate_velocity(hand_motion[:, :, i])\n",
    "# add a singleton dim in 1st place for hand_vel\n",
    "hand_vel = np.expand_dims(hand_vel, axis=0)\n",
    "# Apply the bandpass filter to the ERP data\n",
    "hand_vel = bandpass_filter_fft(hand_vel, .1, 15, 250)\n",
    "# drop singleton dim\n",
    "hand_vel = np.squeeze(hand_vel, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Data and Assign to Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest approach: select indeces in behavior where answerID is > mean\n",
    "# this will work with values obtained from a continuous slider in VR where a clear split at the median is possible\n",
    "\n",
    "high = behavior[behavior['answerID'] > behavior['answerID'].median()].index\n",
    "low = behavior[behavior['answerID'] < behavior['answerID'].median()].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# erp low\n",
    "erp_low = erp[:,:,low]\n",
    "# erp high\n",
    "erp_high = erp[:,:,high]\n",
    "\n",
    "plot_erp_low = np.mean(erp_low[4,:,:], axis=1)\n",
    "plot_erp_high = np.mean(erp_high[4,:,:], axis=1)\n",
    "\n",
    "erp_baseline_tw = np.arange(250, 262)\n",
    "\n",
    "# ! fix for final correct baseline correction -> however this is just for plot\n",
    "plot_erp_low = plot_erp_low - np.mean(plot_erp_low[erp_baseline_tw])\n",
    "plot_erp_high = plot_erp_high - np.mean(plot_erp_high[erp_baseline_tw])\n",
    "\n",
    "# merge both conditions\n",
    "df = pd.DataFrame()\n",
    "# voltage vector\n",
    "df['low'] = plot_erp_low\n",
    "df['high'] = plot_erp_high\n",
    "\n",
    "# melt\n",
    "df = pd.melt(df, value_vars=['low', 'high'], var_name='condition', value_name='voltage')\n",
    "\n",
    "# time vector\n",
    "df['time'] = np.tile(np.arange(0, len(plot_erp_low)),2)# - 50\n",
    "df['time'] = (df['time'] * 1/250 * 1000) - 1000\n",
    "\n",
    "with sns.plotting_context('paper', font_scale = 1.8):\n",
    "\n",
    "    ### Create new plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7,4))\n",
    "    fig.patch.set_alpha(1)\n",
    "\n",
    "    sns.despine() #bottom=True, left=True\n",
    "\n",
    "    # sns.lineplot(x='time', y='voltage', hue='condition', style='control', data=df, ax=ax, errorbar='ci')\n",
    "    sns.lineplot(x='time', y='voltage', hue='condition', data=df, ax=ax, errorbar='ci')\n",
    "    # sns.lineplot(x='time', y='voltage', hue='control', data=df, ax=ax, errorbar='ci')\n",
    "\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Amplitude (Î¼V)')\n",
    "\n",
    "    # xline at 0 with text label 's'\n",
    "    ax.axvline(0, color='black', linestyle='--')\n",
    "    ax.text(.1, 4, 'grab', fontsize=14, rotation=90)\n",
    "\n",
    "    # yline at 0\n",
    "    ax.axhline(0, color='black', linestyle='--')\n",
    "\n",
    "    # mark area of feature extraction add a grey background to the y axis range 100 - 300ms\n",
    "    ax.axvspan(100, 600, color='grey', alpha=0.2, label='features')\n",
    "    ax.axvspan(0, 50, color='grey', alpha=0.1, label='baseline')\n",
    "\n",
    "    # move legend to the right\n",
    "    # ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # save as eps\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig('/Users/lukasgehrke/Desktop/erp_diff.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erp low\n",
    "erp_low = hand_vel[:,low].mean(axis=1)\n",
    "# erp high\n",
    "erp_high = hand_vel[:,high].mean(axis=1)\n",
    "\n",
    "# merge both conditions\n",
    "df = pd.DataFrame()\n",
    "# voltage vector\n",
    "df['low'] = erp_low\n",
    "df['high'] = erp_high\n",
    "\n",
    "# melt\n",
    "df = pd.melt(df, value_vars=['low', 'high'], var_name='condition', value_name='voltage')\n",
    "\n",
    "# time vector\n",
    "df['time'] = np.tile(np.arange(0, len(erp_low)),2)# - 50\n",
    "df['time'] = (df['time'] * 1/250 * 1000) - 1000\n",
    "\n",
    "with sns.plotting_context('paper', font_scale = 1.8):\n",
    "\n",
    "    ### Create new plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7,4))\n",
    "    fig.patch.set_alpha(1)\n",
    "\n",
    "    sns.despine() #bottom=True, left=True\n",
    "\n",
    "    # sns.lineplot(x='time', y='voltage', hue='condition', style='control', data=df, ax=ax, errorbar='ci')\n",
    "    sns.lineplot(x='time', y='voltage', hue='condition', data=df, ax=ax, errorbar='ci')\n",
    "    # sns.lineplot(x='time', y='voltage', hue='control', data=df, ax=ax, errorbar='ci')\n",
    "\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Amplitude (Î¼V)')\n",
    "\n",
    "    # xline at 0 with text label 's'\n",
    "    ax.axvline(0, color='black', linestyle='--')\n",
    "    # ax.text(-5, .1, 'grab', fontsize=14, rotation=90)\n",
    "\n",
    "    # yline at 0\n",
    "    # ax.axhline(0, color='black', linestyle='--')\n",
    "\n",
    "    # ! mark area of feature extraction add a grey background to the y axis range 100 - 300ms\n",
    "    # ax.axvspan(50, 450, color='grey', alpha=0.2, label='features')\n",
    "    # ax.axvspan(0, 50, color='grey', alpha=0.1, label='baseline')\n",
    "\n",
    "    # move legend to the right\n",
    "    # ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # save as eps\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig('/Users/lukasgehrke/Desktop/erp_diff.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EYE Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixation_low = np.array(behavior.loc[low, 'fix_delay']).reshape(1, -1)\n",
    "# fixation_high = np.array(behavior.loc[high, 'fix_delay']).reshape(1, -1)\n",
    "\n",
    "# data = np.concatenate((fixation_low, fixation_high), axis = 1).T\n",
    "# low_class = np.zeros((fixation_low.shape[1], 1))\n",
    "# high_class = np.ones((fixation_high.shape[1], 1))\n",
    "# classes = np.concatenate((low_class, high_class)).ravel()\n",
    "\n",
    "# data_to_plot = pd.DataFrame(data)\n",
    "# data_to_plot['Condition'] = classes\n",
    "# # rename zeros in Condition to low and ones to high\n",
    "# data_to_plot['Condition'] = data_to_plot['Condition'].replace({0: 'low', 1: 'high'})\n",
    "# data_to_plot = data_to_plot.melt(id_vars = 'Condition', value_name = 'amplitude')\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# with sns.plotting_context('paper', font_scale = 1.8):\n",
    "\n",
    "#     ### Create new plot\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(5,4))\n",
    "#     fig.patch.set_alpha(1)\n",
    "\n",
    "#     sns.despine() #bottom=True, left=True\n",
    "\n",
    "#     sns.histplot(x=\"amplitude\", hue=\"Condition\", data=data_to_plot, kde=True, fill=True, stat=\"density\", legend=True)\n",
    "\n",
    "#     # xlabel\n",
    "#     plt.xlabel('Time to first target fixation (ms)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_event = 250\n",
    "data_selection = 144 # 8 windows with 12 samples each\n",
    "samples_of_int = np.arange(sample_event, sample_event+data_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erp_selected = erp[:,samples_of_int,:]\n",
    "erp_selected = erp_selected.reshape(erp_selected.shape[0], 12, 12, erp_selected.shape[2])\n",
    "erp_selected = np.mean(erp_selected, axis=2)\n",
    "baseline = erp_selected[:,0,:]\n",
    "erp_corrected = erp_selected - baseline[:,np.newaxis,:]\n",
    "\n",
    "erp_low = erp_corrected[:,:,low]\n",
    "erp_high = erp_corrected[:,:,high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erp_low_plot = np.mean(erp_low, axis=2)\n",
    "erp_high_plot = np.mean(erp_high, axis=2)\n",
    "\n",
    "# plot them\n",
    "fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "fig.patch.set_alpha(1)\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    sns.lineplot(data=erp_low_plot[i], ax=ax, errorbar='sd')\n",
    "    sns.lineplot(data=erp_high_plot[i], ax=ax, errorbar='sd')\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Amplitude (Î¼V)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean ERP for each class\n",
    "mean_erp_low = np.mean(erp_low, axis=2)\n",
    "mean_erp_high = np.mean(erp_high, axis=2)\n",
    "\n",
    "# Subtract the mean ERP of the high class from the mean ERP of the low class and square the result\n",
    "erp_diff_squared = (mean_erp_low - mean_erp_high) ** 2\n",
    "\n",
    "# Compute the mean over the 12 windows for each channel\n",
    "erp_diff_mean = np.mean(erp_diff_squared, axis=1)\n",
    "\n",
    "# Sort the channels by the absolute differences\n",
    "sorted_channels = np.argsort(np.abs(erp_diff_mean))[::-1]\n",
    "\n",
    "# Print the sorted channels\n",
    "print(\"Sorted channels by differences:\", sorted_channels)\n",
    "\n",
    "# select the top 10 channels\n",
    "top_channels = sorted_channels[:10] # needs to be saved for real-time application\n",
    "\n",
    "# save the top channels\n",
    "with open(path+os.sep+pID+os.sep+'top_channels.json', 'w') as f:\n",
    "    json.dump(top_channels.tolist(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_vel_selected = hand_vel[samples_of_int,:]\n",
    "\n",
    "# hand_vel_selected = hand_vel_selected.reshape(12, 12, hand_vel_selected.shape[1])\n",
    "# hand_vel_selected = np.mean(hand_vel_selected, axis=1)\n",
    "# baseline = hand_vel_selected[:,0,:]\n",
    "# erp_corrected = hand_vel_selected - baseline[:,np.newaxis,:]\n",
    "\n",
    "hand_vel_low = hand_vel_selected[:,low]\n",
    "hand_vel_high = hand_vel_selected[:,high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_vel_low_plot = np.mean(hand_vel_low, axis=1)\n",
    "hand_vel_high_plot = np.mean(hand_vel_high, axis=1)\n",
    "\n",
    "# plot them\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig.patch.set_alpha(1)\n",
    "\n",
    "sns.lineplot(data=hand_vel_low_plot, ax=ax, errorbar='sd', label='Low')\n",
    "sns.lineplot(data=hand_vel_high_plot, ax=ax, errorbar='sd', label='High')\n",
    "ax.set_xlabel('Time (ms)')\n",
    "ax.set_ylabel('Amplitude (Î¼V)')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EYE - gaze velocity? fixation frequency per second?\n",
    "\n",
    "\n",
    "# EYE - time to first target fixation\n",
    "fixation_low = np.array(behavior.loc[low, 'fix_delay']).reshape(1, -1)\n",
    "fixation_high = np.array(behavior.loc[high, 'fix_delay']).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model and Cross-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop baseline dim\n",
    "erp_low = erp_low[top_channels,2:,:]\n",
    "erp_high = erp_high[top_channels,2:,:]\n",
    "erp_low_flattened = erp_low.reshape(-1, erp_low.shape[-1])\n",
    "erp_high_flattened = erp_high.reshape(-1, erp_high.shape[-1])\n",
    "\n",
    "hand_vel_low = np.max(hand_vel_low, axis=0).reshape(1, -1)\n",
    "hand_vel_high = np.max(hand_vel_high, axis=0).reshape(1, -1)\n",
    "\n",
    "# concat all low features\n",
    "#features_low = np.concatenate((erp_low_flattened, fixation_low), axis=0)\n",
    "#features_low = np.concatenate((erp_low_flattened, hand_vel_low, fixation_low), axis=0)\n",
    "features_low = erp_low_flattened\n",
    "# concat all high features\n",
    "#features_high = np.concatenate((erp_high_flattened, fixation_high), axis=0)\n",
    "#features_high = np.concatenate((erp_high_flattened, hand_vel_high, fixation_high), axis=0)\n",
    "features_high = erp_high_flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((features_low, features_high), axis = 1).T\n",
    "low_class = np.zeros((features_low.shape[1], 1))\n",
    "high_class = np.ones((features_high.shape[1], 1))\n",
    "classes = np.concatenate((low_class, high_class)).ravel()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "pickle.dump(scaler, open(path+os.sep+pID+os.sep+'scaler.sav', 'wb'))\n",
    "\n",
    "# generate a train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, classes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LDA(solver='eigen', shrinkage='auto')\n",
    "\n",
    "# Perform cross-validation on the training data\n",
    "cv_scores = cross_val_score(clf, X_train, y_train)\n",
    "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Train the LDA model on the entire training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Set boundaries based on LDA scores for real-time application\n",
    "lda_scores = clf.transform(X_test)\n",
    "# save lda scores\n",
    "with open(path+os.sep+pID+os.sep+'lda_scores.json', 'w') as f:\n",
    "    json.dump(lda_scores.tolist(), f)\n",
    "\n",
    "# boundary_low = np.percentile(lda_scores, 5)\n",
    "# # boundary_low = np.min(lda_scores)\n",
    "# boundary_high = np.percentile(lda_scores, 95)\n",
    "# # boundary_high = np.max(lda_scores)\n",
    "# print(f\"Boundaries: {boundary_low}, {boundary_high}\")\n",
    "\n",
    "# # save low and high boundary\n",
    "# with open(path+os.sep+pID+os.sep+'boundaries.json', 'w') as f:\n",
    "#     json.dump([boundary_low, boundary_high], f)\n",
    "\n",
    "# save model\n",
    "clf.fit(data, classes)\n",
    "filename = path+os.sep+pID+os.sep+'model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "# save BCI params\n",
    "target_class = 1\n",
    "mean_fix_delay = np.mean(behavior['fix_delay'])\n",
    "\n",
    "# 'f1', 'threshold',\n",
    "bci_params = dict(((k, eval(k)) for k in ('target_class', 'mean_fix_delay')))\n",
    "with open(path+os.sep+pID+os.sep+'bci_params.json', 'w') as f:\n",
    "    json.dump(bci_params, f)\n",
    "print(bci_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min max scaling\n",
    "normalized_lda_scores = (lda_scores - lda_scores.min()) / (lda_scores.max() - lda_scores.min())\n",
    "# print(f\"Boundary scores: {normalized_lda_scores}\")\n",
    "\n",
    "with sns.plotting_context('paper', font_scale = 1.8):\n",
    "\n",
    "    ### Create new plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7,4))\n",
    "    fig.patch.set_alpha(1)\n",
    "\n",
    "    sns.despine() #bottom=True, left=True\n",
    "\n",
    "    sns.histplot(normalized_lda_scores, binwidth=0.1, kde=True, ax=ax)\n",
    "    # xline boundaries\n",
    "    # ax.axvline(boundary_low, color='black', linestyle='--')\n",
    "    # ax.axvline(boundary_high, color='black', linestyle='--')\n",
    "    plt.xlabel('Normalized LDA scores')\n",
    "    plt.ylabel('Frequency')\n",
    "    # plt.title('Histogram of decision function scores')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Predicted classes: \", pred_classes)\n",
    "# print(\"Actual classes:    \", y_test)\n",
    "\n",
    "# # confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y_test, pred_classes)\n",
    "# print(\"Confusion matrix: \")\n",
    "# print(cm)\n",
    "\n",
    "# # ROC curve\n",
    "# from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, predictions_prob[:,1])\n",
    "# roc_auc = roc_auc_score(y_test, predictions_prob[:,1])\n",
    "\n",
    "\n",
    "# # plot ROC curve\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# fig.patch.set_alpha(1)\n",
    "\n",
    "# plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.0])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot histogram of scores\n",
    "# data_to_plot = pd.DataFrame(scores)\n",
    "# data_to_plot['Condition'] = X_test\n",
    "# # rename zeros in Condition to low and ones to high\n",
    "# data_to_plot['Condition'] = data_to_plot['Condition'].replace({0: 'low', 1: 'high'})\n",
    "# data_to_plot = data_to_plot.melt(id_vars = 'Condition', value_name = 'score')\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "# with sns.plotting_context('paper', font_scale = 1.8):\n",
    "\n",
    "#     ### Create new plot\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(5,4))\n",
    "#     fig.patch.set_alpha(1)\n",
    "\n",
    "#     sns.despine() #bottom=True, left=True\n",
    "\n",
    "#     sns.histplot(x=\"score\", hue=\"Condition\", data=data_to_plot, kde=True, fill=True, stat=\"density\", legend=True)\n",
    "\n",
    "#     # add xlines for boundaries variable\n",
    "#     for boundary in boundaries:\n",
    "#         ax.axvline(boundary, color='black', linestyle='--')\n",
    "\n",
    "#     # xlabel\n",
    "#     plt.xlabel('LDA score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_roc_curve(fpr, tpr):\n",
    "#     plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "#     plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# def interp_roc_curve(true, score, by ='fp', byval = np.linspace(0,1,101)):\n",
    "#     fp, tp, th =  roc_curve(true, score)\n",
    "#     data = {'fp': fp, 'tp': tp, 'th': th}\n",
    "#     interpData = {}\n",
    "#     for k,v in data.items():\n",
    "#         if k==by:\n",
    "#             interpData[k] = byval\n",
    "#         else:\n",
    "#             interpData[k] = np.interp(byval, data[by], data[k])\n",
    "#     roc = pd.DataFrame.from_dict(interpData)\n",
    "#     return(roc)\n",
    "\n",
    "# roc = interp_roc_curve(classes, predictions_prob[:,1])\n",
    "\n",
    "# false_positive_rate, recall, thresholds = roc_curve(classes, predictions_prob[:,1])\n",
    "\n",
    "# np.savetxt(path+os.sep+pID+os.sep+'fpr.csv', roc.fp, delimiter=',')\n",
    "# np.savetxt(path+os.sep+pID+os.sep+'recall.csv', roc.tp, delimiter=',')\n",
    "\n",
    "# roc_auc = auc(false_positive_rate, recall)\n",
    "# plot_roc_curve(false_positive_rate, recall)\n",
    "\n",
    "# optimal_idx = np.argmax(recall - false_positive_rate)\n",
    "# optimal_threshold = thresholds[optimal_idx]\n",
    "# print(\"Threshold value is:\", optimal_threshold)\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "# f1 = f1_score(classes, pred_classes)\n",
    "# print(\"F1 Score: \"+ str(f1_score(classes, pred_classes)))\n",
    "\n",
    "# # threshold = cv_results.mean()\n",
    "# threshold = np.min(thresholds[false_positive_rate<.2])\n",
    "# print(\"Threshold used is:\", threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
